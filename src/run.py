import numpy as np
import matplotlib.pyplot as plt

from ridge import Ridge
from lasso import Lasso
from data_generation import FrankeData, TerrainData
from plotter import (
    heat_plot,
    line_plot,
    plot_confidence_interval,
    side_by_side_line_plot,
    surface_plot_raveled,
)
from ordinary_least_squares import OrdinaryLeastSquares

from config import DEFAULT_NOISE_LEVEL, DEFAULT_TEST_SIZE


def generate_franke_dataset(test_size=None, preview=False):
    """Generates a franke dataset

    Parameters
    ----------
        test_size : float
            The size of the test data, compared to the train data
        preview : bool
            Gives data optimized for plotting if True

    Returns
    -------
        data : FrankeData
            The data generated by the method
    """
    if preview:
        return FrankeData(100, random_positions=False, random_noise=False)
    return FrankeData(30, test_size=test_size)


def generate_terrain_dataset(test_size=None, preview=False):
    """Generates a terrain dataset

    Parameters
    ----------
        test_size : float
            The size of the test data, compared to the train data
        preview : bool
            Gives data optimized for plotting if True

    Returns
    -------
        data : TerrainData
            The data generated by the method
    """
    if preview:
        return TerrainData("data/geodata.tif", scale_data_size=0.1)
    return TerrainData("data/geodata.tif", test_size=test_size, scale_data_size=0.01)


def preview_franke_function(N):
    """Plots a preview of data from the franke function

    Parameters
    ----------
        N : int
            The number of elements in each direction
    """
    franke_data = FrankeData(N, random_positions=True, random_noise=False)
    franke_data_noisy = FrankeData(N, random_positions=False)
    surface_plot_raveled(
        "Franke function and noisy franke function",
        x=franke_data.x,
        y=franke_data.y,
        z_arr=[[franke_data.z, franke_data_noisy.z]],
        subtitles=[["Franke function", "Franke function noisy"]],
        dimensions=franke_data.dimensions,
        filename="franke_preview.pdf",
    )


def preview_terrain():
    """Plots a preview of the terrain"""
    data = TerrainData("data/geodata.tif", scale_data_size=0.2)

    surface_plot_raveled(
        title="Terrain data",
        x=data.x,
        y=data.y,
        z_arr=[[data.z]],
        subtitles=[["real"]],
        dimensions=data.dimensions,
        filename="terrain_preview.pdf",
    )


def ols_mse_r2(
    data_generator,
    degrees,
    data_name,
    repeats_per_degree,
    test_size=DEFAULT_TEST_SIZE,
):
    """Plots the MSE and R2 performance of the OLS method by running multiple iterations per degree

    Parameters
    ----------
        data_generator : str
            The function used for generating data
        degrees : int[]
            The degrees for which to test performance
        data_name : str
            The name of the method used to generate data
        repeats_per_degree : int
            The number of times to access performance per degree
        test_size : float
            The size of the test data, compared to the train data
    """
    mse_train_errors = []
    mse_test_errors = []

    r2_train_errors = []
    r2_test_errors = []

    for d in degrees:
        mse_train_errors_degree = []
        mse_test_errors_degree = []

        r2_train_errors_degree = []
        r2_test_errors_degree = []

        for _ in range(repeats_per_degree):
            data = data_generator(test_size)
            ols = OrdinaryLeastSquares(d)
            ols.fit(data.x_train, data.y_train, data.z_train)

            z_tilde_train = ols.predict(data.x_train, data.y_train)
            z_tilde_test = ols.predict(data.x_test, data.y_test)

            mse_train = ols.MSE(data.z_train, z_tilde_train)
            mse_test = ols.MSE(data.z_test, z_tilde_test)

            mse_train_errors_degree.append(mse_train)
            mse_test_errors_degree.append(mse_test)

            r2_train = ols.R2(data.z_train, z_tilde_train)
            r2_test = ols.R2(data.z_test, z_tilde_test)

            r2_train_errors_degree.append(r2_train)
            r2_test_errors_degree.append(r2_test)

        mse_train_errors.append(sum(mse_train_errors_degree) / repeats_per_degree)
        mse_test_errors.append(sum(mse_test_errors_degree) / repeats_per_degree)

        r2_train_errors.append(sum(r2_train_errors_degree) / repeats_per_degree)
        r2_test_errors.append(sum(r2_test_errors_degree) / repeats_per_degree)

    #  best_mse_test_error_degree = degrees[np.argmin(mse_test_errors)]

    side_by_side_line_plot(
        title=f"MSE and R2 for different degrees with OLS model ({data_name})",
        plot_one_title="MSE",
        plot_one_x_data=[degrees, degrees],
        plot_one_y_data=[mse_train_errors, mse_test_errors],
        plot_one_labels=["Train errors", "Test errors"],
        plot_one_x_label="degree",
        plot_one_y_label="Error",
        plot_two_title="R2",
        plot_two_x_data=[degrees, degrees],
        plot_two_y_data=[r2_train_errors, r2_test_errors],
        plot_two_labels=["Train score", "Test score"],
        plot_two_x_label="degree",
        plot_two_y_label="score",
        filename=f"ols_mse_r2_{data_name}.pdf",
    )


def ols_confidence_intervals(data, degree, data_name):
    """Computes and plots the confidence intervals for the model

    Parameters
    ----------
        data : data_generation.Data
            The data for which to compute the confidence intervals
        degree : int
            The degree for which to compute the confidence intervals
        data_name : str
            The name of the method used to generate data
    """
    #  data = FrankeData(20)
    ols = OrdinaryLeastSquares(degree)
    ols.fit(data.x, data.y, data.z)

    z_tilde = ols.predict(data.x, data.y)

    confidence_intervals, sigma_betas, sigma_squared = ols.confidence_intervals(
        data.x, data.y, data.z, z_tilde
    )

    plot_confidence_interval(
        title=f"Confidence intervals for OLS and {data_name} with degree {degree} ({data_name})",
        x=range(len(sigma_betas)),
        y=ols.beta,
        y_err=sigma_betas,
        x_label="beta",
        y_label="value",
        filename=f"ols_confidence_intervals_{data_name}.pdf",
    )


def bootstrap_bias_variance(data, bootstrap_repeats, degrees, data_name):
    """Computes and plots the bias and variance using bootstrap

    Parameters
    ----------
        data : data_generation.Data
            The data for which to compute the confidence intervals
        bootstrap_repeats : int
            The number of times to do bootstrap
        degrees : int[]
            The degrees for which to test performance
        data_name : str
            The name of the method used to generate data
    """
    bias = []
    variance = []
    for degree in degrees:
        ols = OrdinaryLeastSquares(degree)
        bootstrap_z_tilde = ols.bootstrap(data, bootstrap_repeats)
        bias.append(ols.bias(data.z_test, bootstrap_z_tilde))
        variance.append(ols.variance(bootstrap_z_tilde))

    side_by_side_line_plot(
        title=f"Bias and variance from bootstrap ({data_name})",
        plot_one_title="Bias",
        plot_one_x_data=[degrees],
        plot_one_y_data=[bias],
        plot_one_labels=["Bias"],
        plot_one_x_label="degree",
        plot_one_y_label="bias",
        plot_two_title="Variance",
        plot_two_x_data=[degrees],
        plot_two_y_data=[variance],
        plot_two_labels=["Variance"],
        plot_two_x_label="degrees",
        plot_two_y_label="variance",
        filename=f"bootstrap_bias_variance_{data_name}.pdf",
    )


def bootstrap_vs_cross_validation(data, folds, bootstrap_repeats, degrees, data_name):
    """Computes and plots the bootstrap performance vs the cross validation

    Parameters
    ----------
        data : data_generation.Data
            The data for which to compute the confidence intervals
        folds : int
            The number of k-folds to use for the cross validation
        bootstrap_repeats : int
            The number of times to do bootstrap
        degrees : int[]
            The degrees for which to test performance
        data_name : str
            The name of the method used to generate data
    """
    #  data = FrankeData(data_N)
    mse_k_fold = []
    mse_bootstrap = []
    for degree in degrees:
        ols = OrdinaryLeastSquares(degree)
        mse_k_fold.append(ols.k_fold_cross_validation(data, folds))
        data.train_test_split(DEFAULT_NOISE_LEVEL)
        bootstrap_z_tilde = ols.bootstrap(data, bootstrap_repeats)
        mse_bootstrap.append(ols.MSE(data.z_test, bootstrap_z_tilde))

    line_plot(
        title=f"MSE for bootstrap and k-fold ({data_name})",
        x_datas=[degrees, degrees],
        y_datas=[mse_k_fold, mse_bootstrap],
        data_labels=["k-fold cross-validation", "bootstrap"],
        x_label="degree",
        y_label="MSE",
        filename=f"bootstrap_cross_validation_{data_name}.pdf",
    )


def optimal_ols_parameter(data, degrees):
    """Find the best degree for the ordinary least squares

    Parameters
    ----------
        data : data_generation.Data
            The data for which to compute the confidence intervals
        degrees : int[]
            The degrees for which to test performance

    Returns
    -------
        best_mse_degree : int
            The degree with the best test MSE performance
    """
    best_mse = 0
    best_mse_degree = -1
    for degree in degrees:
        ols = OrdinaryLeastSquares(degree)
        ols.fit(data.x_train, data.y_train, data.z_train)
        z_test_tilde = ols.predict(data.x_test, data.y_test)
        mse = ols.MSE(data.z_test, z_test_tilde)
        if best_mse_degree == -1 or mse < best_mse:
            best_mse_degree = degree
            best_mse = mse
    return best_mse_degree


def optimal_regularized_parameters(
    data, degrees, Model, log_lambda_from, log_lambda_to, number_of_lambdas, data_name
):
    """Compute and plot the optimal regularized parameters for a model

    Parameters
    ----------
        data : data_generation.Data
            The data for which to compute the confidence intervals
        degrees : int[]
            The degrees for which to test performance
        Model : linear_regression_model
            The model for which to find optimal regularized parameters
        log_lambda_from : float
            The start value for finding the optimal regularized parameters for
        log_lambda_to :
            The end value for finding the optimal regularized parameters for
        number_of_lambdas : int
            The number of lambdas to test performance for
        data_name : str
            The name of the method used to generate data

    Returns
    -------
        degree : int
            The optimal degree for the regularized model
        lambda : float
            The optimal lambda for the regularized model
    """
    lambdas = np.logspace(log_lambda_from, log_lambda_to, number_of_lambdas)[::-1]
    mse_table = np.zeros((number_of_lambdas, len(degrees)))
    for i, degree in enumerate(degrees):
        for j, lambda_ in enumerate(lambdas):
            model = Model(degree, lambda_)
            model.fit(data.x_train, data.y_train, data.z_train)
            z_test_tilde = model.predict(data.x_test, data.y_test)

            mse = model.MSE(data.z_test, z_test_tilde)
            mse_table[j, i] = mse

    min_lambda, min_degree = np.unravel_index(mse_table.argmin(), mse_table.shape)
    min_mse = mse_table[min_lambda, min_degree]

    heat_plot(
        title=f"MSE performance for {model} on {data_name}",
        table_values=mse_table,
        xticklabels=degrees,
        yticklabels=np.log10(lambdas),
        x_label="degree",
        y_label="lambda (log10)",
        selected_idx=(min_degree, min_lambda),
        filename=f"mse_heat_plot_{data_name}_{model}.pdf",
    )

    return degrees[min_degree], lambdas[min_lambda]


def preview_all_models(
    data, ols_degree, ridge_degree, ridge_lambda, lasso_degree, lasso_lambda, data_name
):
    """Plot the real value and all the predicted ones

    Parameters
    ----------
        data : data_generation.Data
            The data for which to compute the confidence intervals
        ols_degree : int
            The degree for the OLS-model
        ridge_degree : int
            The degree for the ridge-model
        ridge_lambda : float
            The lambda value for the ridge-model
        lasso_degree : int
            The degree for the lasso-model
        lasso_lambda :
            The lambda value for the lasso-model
        data_name : str
            The name of the method used to generate data
    """
    ols = OrdinaryLeastSquares(ols_degree)
    ols.fit(data.x, data.y, data.z)
    z_tilde_ols = ols.predict(data.x, data.y)

    ridge = Ridge(ridge_degree, ridge_lambda)
    ridge.fit(data.x, data.y, data.z)
    z_tilde_ridge = ridge.predict(data.x, data.y)

    lasso = Lasso(lasso_degree, lasso_lambda)
    lasso.fit(data.x, data.y, data.z)
    z_tilde_lasso = lasso.predict(data.x, data.y)

    print("MSE OLS:", ols.MSE(data.z, z_tilde_ols))
    print("MSE RIDGE:", ridge.MSE(data.z, z_tilde_ridge))
    print("MSE LASSO:", lasso.MSE(data.z, z_tilde_lasso))

    surface_plot_raveled(
        title=f"Data and predictions ({data_name})",
        x=data.x,
        y=data.y,
        z_arr=[[data.z, z_tilde_ols], [z_tilde_ridge, z_tilde_lasso]],
        subtitles=[["data", "ols"], ["ridge", "lasso"]],
        dimensions=data.dimensions,
        filename=f"prediction_all_models_{data_name}.pdf",
    )


def run_analysis_for_data(data_generator, data_name):
    """Run the main analysis with everything for one data type

    Parameters
    ----------
        data_generator : str
            The function used for generating data
        data_name : str
            The name of the method used to generate data
    """
    train_test_data = data_generator(test_size=DEFAULT_TEST_SIZE)
    raw_data = data_generator()

    ols_mse_r2(
        data_generator=data_generator,
        data_name=data_name,
        degrees=list(range(1, 21)),
        repeats_per_degree=100,
    )

    optimal_ols_degree = optimal_ols_parameter(train_test_data, list(range(1, 21)))

    optimal_ridge_degree, optimal_ridge_lambda = optimal_regularized_parameters(
        data=train_test_data,
        degrees=list(range(2, 21)),
        Model=Ridge,
        log_lambda_from=-20,
        log_lambda_to=-1,
        number_of_lambdas=20,
        data_name=data_name,
    )

    optimal_lasso_degree, optimal_lasso_lambda = optimal_regularized_parameters(
        data=train_test_data,
        degrees=list(range(2, 21)),
        Model=Lasso,
        log_lambda_from=-20,
        log_lambda_to=-3,
        number_of_lambdas=18,
        data_name=data_name,
    )
    #  #
    #  #  #  data = FrankeData(50, random_noise=False, random_positions=False)
    #  #
    preview_data = data_generator(preview=True)

    preview_all_models(
        preview_data,
        optimal_ols_degree,
        optimal_ridge_degree,
        optimal_ridge_lambda,
        optimal_lasso_degree,
        optimal_lasso_lambda,
        data_name=data_name,
    )

    confidence_data = data_generator()

    ols_confidence_intervals(
        confidence_data, degree=optimal_ols_degree, data_name=data_name
    )

    bootstrap_bias_variance(
        data=train_test_data,
        bootstrap_repeats=150,
        degrees=list(range(1, 11)),
        data_name=data_name,
    )
    bootstrap_vs_cross_validation(
        data=raw_data,
        folds=5,
        bootstrap_repeats=1000,
        degrees=list(range(1, 11)),
        data_name=data_name,
    )


def run_analysis():
    """Run the main analysis, runs on set seed"""
    np.random.seed(31415)

    preview_franke_function(100)
    preview_terrain()

    run_analysis_for_data(generate_franke_dataset, "franke function")
    run_analysis_for_data(generate_terrain_dataset, "terrain data")


if __name__ == "__main__":
    run_analysis()
